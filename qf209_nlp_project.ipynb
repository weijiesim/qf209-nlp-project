{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_mdkZqU2Zhnq",
        "outputId": "4ce0b414-8d9d-4f4d-8fd2-932158169f7f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "from dash_bootstrap_templates import load_figure_template\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import RidgeCV, Ridge\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "import ast\n",
        "from gensim import corpora, models\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models import CoherenceModel\n",
        "import spacy\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "import scipy\n",
        "from scipy.optimize import minimize\n",
        "from pmdarima import auto_arima\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "load_figure_template('minty')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_pkl_file(object, filepath):\n",
        "    # Retrieve directory\n",
        "    directory = os.path.dirname(filepath)\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        print(f\"Folder created at {directory}\")\n",
        "    with open(filepath, 'wb') as file:\n",
        "        pickle.dump(object, file)\n",
        "\n",
        "def load_pkl_file(filepath):\n",
        "    with open(filepath, 'rb') as file:\n",
        "        return pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "REFRESH = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_1 = pd.read_csv(\"data/daily_financial_news/analyst_ratings_processed.csv\", index_col=0)\n",
        "data_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_1['date'] = data_1['date'].str.split(' ', expand=True).iloc[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_1['stock'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVlMohoBlTJQ",
        "outputId": "15579c96-a538-480e-cf36-81553f02c734"
      },
      "outputs": [],
      "source": [
        "data_1.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Drop Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKt6rDWBlk8l",
        "outputId": "9512fd8d-8077-4237-937c-e87a35976c89"
      },
      "outputs": [],
      "source": [
        "print(data_1.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9pDiHR3nCvC",
        "outputId": "606a9af2-c319-4559-b501-5f7cdd954638"
      },
      "outputs": [],
      "source": [
        "print(data_1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_1[data_1['date'].isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV5Xn1-2oMTG"
      },
      "outputs": [],
      "source": [
        "data_1.dropna(subset=['date'],inplace=True)\n",
        "data_1.dropna(subset=['stock'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkszMKzlpVnL",
        "outputId": "f2b99e34-dab9-4f73-805c-c1db92b21862"
      },
      "outputs": [],
      "source": [
        "print(data_1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG6ydygqpZx1",
        "outputId": "9fff9776-66d4-42ad-9307-309dd0fbd9f6"
      },
      "outputs": [],
      "source": [
        "print(data_1.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lthUY-R-phFG",
        "outputId": "39c496c4-1489-4457-93e0-5e88c8054b29"
      },
      "outputs": [],
      "source": [
        "data_1.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filter stocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter dataset down to stocks with top 100 number of headlines\n",
        "top_100_stocks_by_headlines = data_1.groupby('stock').size().reset_index(name='size').sort_values('size', ascending=False).reset_index(drop=True).iloc[:100]\n",
        "top_100_stocks_by_headlines.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_1 = data_1[data_1['stock'].isin(top_100_stocks_by_headlines.stock)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean Text Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bysKZg9qtnrg"
      },
      "outputs": [],
      "source": [
        "data_1['title'] = data_1['title'].str.lower()\n",
        "data_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Remove Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jUv6dT5vpIp"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return ''.join([char for char in text if char not in string.punctuation and not char.isdigit()])\n",
        "\n",
        "data_1['title'] = data_1['title'].apply(remove_punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hHyB2atzvvgq",
        "outputId": "9c27a854-4218-4cd1-9f3f-c40293e8d38a"
      },
      "outputs": [],
      "source": [
        "data_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GdlIDQsTwJxt",
        "outputId": "3c5dfcd6-b1f5-4462-92e0-24d99fcaf567"
      },
      "outputs": [],
      "source": [
        "data_1['tokens'] = data_1['title'].apply(lambda x: x.split())\n",
        "data_1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Remove stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUEjDSAwwSjK",
        "outputId": "4b5df763-3a4c-42db-ad0a-ff33b2c5c7aa"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "data_1['tokens'] = data_1['tokens'].apply(lambda x: [word for word in x if word not in stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mkPxf-CgwozT",
        "outputId": "2b6e2cf8-d361-48eb-ae5b-70632f6547dd"
      },
      "outputs": [],
      "source": [
        "data_1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lemmatize tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7fTt-K3xJvz",
        "outputId": "5c7566e1-e106-4449-ea98-8f15cb9a1c93"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "data_1['tokens'] = data_1['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "15KCoy4qxkxx",
        "outputId": "dc3de5f1-a6b2-4628-ac4d-a94ac0f98b39"
      },
      "outputs": [],
      "source": [
        "data_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XUau0f0GxULI",
        "outputId": "2bc02e85-0e41-43ce-bc32-64d619832a29"
      },
      "outputs": [],
      "source": [
        "data_1['preprocessed_text'] = data_1['tokens'].apply(' '.join)\n",
        "data_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDMEu5K2x4L6",
        "outputId": "20fc393c-bef0-41bf-ce79-d63044de3c74"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "# NLTK Sentiment Intensity Analyzer uses a 'Bag of Words' approach\n",
        "# it removes stop words and scores each word individually before compounding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_duplicate = data_1.copy()\n",
        "data_duplicate['sentiment_score'] = data_duplicate['preprocessed_text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
        "data_duplicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0nlV-P20K_8",
        "outputId": "2c43f90d-c726-46e3-c5d3-999274766fdf"
      },
      "outputs": [],
      "source": [
        "data_duplicate['sentiment_score'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGBvIQCZ2Ew6",
        "outputId": "ce24972b-4612-4b4d-86f8-32e1d288a9c0"
      },
      "outputs": [],
      "source": [
        "data_duplicate.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signals_df = data_duplicate.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signals_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# There are some stocks that have multiple news articles on the same day\n",
        "# Have to handle these cases\n",
        "# non_dup_signals_df = signals_df.groupby(['date', 'stock'])['sentiment_score'].mean().reset_index(name='sentiment_score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Pull yfinance Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tickers = data_duplicate.stock.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_date, end_date = data_duplicate.date.sort_values().iloc[0], data_duplicate.date.sort_values().iloc[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = yf.download(list(tickers), start=start_date, end=end_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "adj_close_data = data['Adj Close']\n",
        "adj_close_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tickers that don't have data\n",
        "missing_data_tickers = adj_close_data.columns[adj_close_data.isna().sum()/adj_close_data.shape[0] == 1]\n",
        "\n",
        "# Drop missing tickers\n",
        "adj_close_data = adj_close_data.drop(columns=missing_data_tickers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop other tickers\n",
        "adj_close_data = adj_close_data.dropna(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "any(adj_close_data.isna().sum() > 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "returns_df = adj_close_data.pct_change().dropna().reset_index().rename(columns={'Date': 'date'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "returns_df_melt = returns_df.melt(id_vars='date', var_name='stock', value_name='daily_returns')\n",
        "returns_df_melt['date'] = pd.to_datetime(returns_df_melt['date'])\n",
        "returns_df_melt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "returns_df_melt.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Returns Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Plot the Daily Stock Returns versus Date\n",
        "\n",
        "n = len(returns_df.set_index('date').columns)\n",
        "col = 8 #specify the number of columns for the plot\n",
        "row = int(np.ceil(n/col)) #specify the number of rows\n",
        "fig_hei = row * 3 #specify height for the plot\n",
        "fig_wid = col * 4 #specify width for the lot\n",
        "\n",
        "ax = returns_df.set_index('date').plot(subplots=True, layout=(row ,col), figsize=(fig_wid, fig_hei),\n",
        "             sharey=True, sharex=True, #share y and x axis for the subplots\n",
        "             title = '(Daily) Stock Returns versus Date')\n",
        "\n",
        "for i in range(col): #add x tickers to the top of the plot\n",
        "    ax[0,i].xaxis.set_tick_params(which='both', top = True, labeltop=True, labelrotation=40)\n",
        "\n",
        "fig = ax[0,0].get_figure()\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=0.93) #to indirectly adjust the location of the title\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Summary Statistics for each Asset\n",
        "Freq = 252 # Daily trading frequency\n",
        "\n",
        "# Functions for annualizing returns and standard deviation; x is a scalar input\n",
        "def ann_ret(x):\n",
        "    return (x+1)**Freq-1\n",
        "def ann_std(x):\n",
        "    return x*np.sqrt(Freq)\n",
        "\n",
        "# Function used to find the Annualized geometric mean of x [note: x is series of weekly data]\n",
        "def ann_geo_mean(x):\n",
        "    n = len(x)\n",
        "    return np.exp(np.sum(np.log(1+x)) * Freq / n) - 1\n",
        "\n",
        "# Function used to find the Annualized Sharpe Ratio of x; x is a series of simple returns\n",
        "def ann_sr(x):\n",
        "    n = len(x)\n",
        "    ret_expected = np.sum(x)/n # more widely used as arithmetic mean in sharpe ratio calculation\n",
        "    ret_avg = np.sum(x)/n\n",
        "    std_dev = np.sqrt( np.sum( (x - ret_avg)**2 ) / n ) # Assuming no risk free returns to be consistent with calculations of other strats\n",
        "    annu_ret_expected = (ret_expected+1)**Freq-1\n",
        "    annu_std_dev = std_dev * np.sqrt(Freq)\n",
        "    return annu_ret_expected/annu_std_dev\n",
        "\n",
        "# Function used to find the Maximum drawdown\n",
        "def mdd(x):\n",
        "    wealth = (x+1).cumprod() #x is a return vector\n",
        "    cummax = wealth.cummax() #determine cumulative maximum value\n",
        "    drawdown = wealth/cummax - 1 #calculate drawdown vector\n",
        "    return drawdown.min()\n",
        "# Output summary statistics information:\n",
        "# Calculate and show the Mean, Geometric Mean, and Standard Deviation, Sharpe Ratio, Maximum Drawdown (with 2 decimals)\n",
        "n_dec = 2\n",
        "SumStat = pd.DataFrame(index = returns_df.set_index('date').columns)\n",
        "SumStat['Geo Mean(Annu,%)'] = np.round( returns_df.set_index('date').apply(ann_geo_mean)*100, n_dec)\n",
        "SumStat['Volatility(Annu,%)'] = np.round( ann_std(returns_df.set_index('date').std())*100 , n_dec)\n",
        "SumStat['Sharpe Ratio (Annu)'] = np.round( returns_df.set_index('date').apply(ann_sr) , n_dec)\n",
        "SumStat['Max Drawdown(%)'] = np.round(returns_df.set_index('date').apply(mdd)*100, n_dec)\n",
        "display(SumStat)\n",
        "sumstat_fig = px.bar(SumStat.drop(columns='Sharpe Ratio (Annu)'))\n",
        "sumstat_fig.update_layout(title='Summary statistics of stocks',\n",
        "                          xaxis_title=\"Ticker\", yaxis_title=\"Value\",\n",
        "                          legend_title=\"Statistic\")\n",
        "sumstat_fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Covariance Matrix\n",
        "returns_df_cov_mat = returns_df.set_index('date').cov()\n",
        "returns_df_cov_annu = returns_df_cov_mat * Freq\n",
        "display(returns_df_cov_annu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Save Returns Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save returns df as pickle\n",
        "save_pkl_file(returns_df, 'cache/dataframes/returns_df.pkl')\n",
        "save_pkl_file(returns_df_melt, 'cache/dataframes/returns_df_melt.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signals_df['date'] = pd.to_datetime(signals_df['date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3 Merge returns data with signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_df = pd.merge(returns_df_melt, signals_df, on=['date', 'stock']).dropna()\n",
        "merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count number of stocks per date\n",
        "merged_df['num_stocks_by_date'] = merged_df.groupby('date').transform('size')\n",
        "\n",
        "# Select data where there were at least 10 stocks for each date\n",
        "merged_df_filtered = merged_df[merged_df['num_stocks_by_date'] >= 10]\n",
        "\n",
        "# Drop num_stocks_by_date column\n",
        "ml_df = merged_df_filtered.drop(columns='num_stocks_by_date').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Build Machine Learning Dataframes and Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional Feature Engineer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Day of Week Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_df['date'] = pd.to_datetime(ml_df['date'])\n",
        "ml_df['day_of_week'] = ml_df['date'].dt.dayofweek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Topic Feature using Latent Dirichlet Allocation (LDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def safe_literal_eval(s):\n",
        "    try:\n",
        "        return ast.literal_eval(s)\n",
        "    except (ValueError, SyntaxError):\n",
        "        return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_df['tokens'] = ml_df['tokens'].apply(safe_literal_eval)\n",
        "\n",
        "# Create Dictionary (takes 5 minutes to run)\n",
        "id2word = corpora.Dictionary(ml_df['tokens'])\n",
        "\n",
        "# Term Document Frequency (Corpus)\n",
        "corpus = [id2word.doc2bow(text) for text in ml_df['tokens']]\n",
        "\n",
        "lda_model = LdaModel(corpus=corpus, id2word=id2word, num_topics=10, random_state=42, passes=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect Topics\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
        "\n",
        "# Inspect Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=ml_df['tokens'], dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to get the dominant topic\n",
        "def get_dominant_topic(lda_model, corpus):\n",
        "    dominant_topics = []\n",
        "    for doc_topics in lda_model[corpus]:\n",
        "        # Sort the topics by their assigned proportions\n",
        "        sorted_topics = sorted(doc_topics, key=lambda x: x[1], reverse=True)\n",
        "        # Get the topic number of the highest proportion topic\n",
        "        dominant_topic = sorted_topics[0][0]\n",
        "        dominant_topics.append(dominant_topic)\n",
        "    return dominant_topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the dominant topic on the data\n",
        "ml_df['dominant_topic'] = get_dominant_topic(lda_model, corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Entities Count Feature using Named Entity Recognizer (NER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the spaCy model\n",
        "spacy_nlp_model = spacy.load('en_core_web_sm')\n",
        "\n",
        "def extract_entities(text):\n",
        "    # Process the text with the NER model\n",
        "    doc = spacy_nlp_model(text)\n",
        "\n",
        "    # Extract entities that are either PERSON or ORG (companies). You can adjust this as needed.\n",
        "    entities = [ent.text for ent in doc.ents if ent.label_ in ['PERSON', 'ORG']]\n",
        "\n",
        "    return entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract entities from data (takes 10 - 20 minutes to run)\n",
        "ml_df['entities'] = ml_df['preprocessed_text'].apply(extract_entities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_df['entities_count'] = ml_df['entities'].apply(len)\n",
        "ml_df.drop('entities', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_df_final = ml_df[['date', 'stock', 'daily_returns', 'sentiment_score', 'day_of_week', 'dominant_topic', 'entities_count']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save to pkl file\n",
        "save_pkl_file(ml_df_final, 'cache/dataframes/ml_df.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Machine Learning Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Functions for Train Test Split, One Hot Encoding, Scoring\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define function for train test split\n",
        "def ts_train_test_split(data, test_size):\n",
        "    \"\"\"Takes in data and output train set and test set in that order\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame or pd.Series): Data to split into train and test\n",
        "        test_size (float): Percentage for test size\n",
        "\n",
        "    Returns:\n",
        "        tuple: train set, test set\n",
        "    \"\"\"\n",
        "    train_size = 1-test_size\n",
        "    train_idx = round(data.shape[0] * train_size)\n",
        "    return data.iloc[:train_idx], data.iloc[train_idx:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_hot_encode(X_train, X_valid, columns_to_encode):\n",
        "    # Initialize OneHotEncoder\n",
        "    one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "\n",
        "    # Drop date column if it exists\n",
        "    X_train = X_train.drop(columns=['date'], errors='ignore')\n",
        "    X_valid = X_valid.drop(columns=['date'], errors='ignore')\n",
        "\n",
        "    # Create empty DataFrames to accumulate our one-hot encoded columns\n",
        "    OH_X_train_accum = X_train.drop(columns=columns_to_encode)\n",
        "    OH_X_valid_accum = X_valid.drop(columns=columns_to_encode)\n",
        "\n",
        "    for col in columns_to_encode:\n",
        "        # One-hot Encode the current column for Training and Validation Data\n",
        "        OH_cols_train = pd.DataFrame(one_hot_encoder.fit_transform(X_train[[col]]))\n",
        "        OH_cols_valid = pd.DataFrame(one_hot_encoder.transform(X_valid[[col]]))\n",
        "\n",
        "        # Assign Column Names after One-Hot Encoding and Restore Index\n",
        "        OH_cols_train.columns = one_hot_encoder.get_feature_names_out([col])\n",
        "        OH_cols_valid.columns = one_hot_encoder.get_feature_names_out([col])\n",
        "        OH_cols_train.index = X_train.index\n",
        "        OH_cols_valid.index = X_valid.index\n",
        "\n",
        "        # Concatenate One-Hot Encoded Columns to the accumulating DataFrame\n",
        "        OH_X_train_accum = pd.concat([OH_X_train_accum, OH_cols_train], axis=1)\n",
        "        OH_X_valid_accum = pd.concat([OH_X_valid_accum, OH_cols_valid], axis=1)\n",
        "\n",
        "    # Ensure all columns have string type\n",
        "    OH_X_train_accum.columns = OH_X_train_accum.columns.astype(str)\n",
        "    OH_X_valid_accum.columns = OH_X_valid_accum.columns.astype(str)\n",
        "\n",
        "    return OH_X_train_accum, OH_X_valid_accum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def score_model(model, X_t, X_v, y_t, y_v):\n",
        "    # Fit Model\n",
        "    model.fit(X_t, y_t)\n",
        "\n",
        "    # Predict\n",
        "    preds = model.predict(X_v)\n",
        "\n",
        "    # Check MAE\n",
        "    mae = mean_absolute_error(y_v, preds)\n",
        "    mse = mean_squared_error(y_v, preds)\n",
        "    return preds, mae, mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_df_final= load_pkl_file('cache/dataframes/ml_df.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split Data into Features and Target\n",
        "# Sort values by date\n",
        "X = ml_df_final.sort_values(\"date\").drop('daily_returns', axis=1).reset_index(drop=True)\n",
        "y = ml_df_final.sort_values(\"date\")['daily_returns'].reset_index(drop=True)\n",
        "\n",
        "# Split Data into Training and Validation Sets\n",
        "X_train, X_valid = ts_train_test_split(X, test_size=0.2)\n",
        "y_train, y_valid = ts_train_test_split(y, test_size=0.2)\n",
        "\n",
        "# Use one_hot_encode function to get One-Hot Encoded Training and Validation Data\n",
        "columns_to_encode = ['stock', 'day_of_week', 'dominant_topic']\n",
        "OH_X_train, OH_X_valid = one_hot_encode(X_train, X_valid, columns_to_encode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_pkl_file(OH_X_train, 'cache/dataframes/OH_X_train.pkl')\n",
        "save_pkl_file(OH_X_valid, 'cache/dataframes/OH_X_valid.pkl')\n",
        "save_pkl_file(X_valid, 'cache/dataframes/X_valid.pkl')\n",
        "save_pkl_file(y_train, 'cache/dataframes/y_train.pkl')\n",
        "save_pkl_file(y_valid, 'cache/dataframes/y_valid.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if REFRESH :\n",
        "    #Fit linear model\n",
        "    linear_model = LinearRegression()\n",
        "    preds_linear, mae_linear, mse_linear = score_model(linear_model, OH_X_train, OH_X_valid, y_train, y_valid)\n",
        "    print(f\"Mean Absolute Error with Linear Regression: {mae_linear}\")\n",
        "    print(f\"Mean Squared Error with Linear Regression: {mse_linear}\")\n",
        "    save_pkl_file(linear_model, filepath='cache/ml_models/linear_model.pkl')\n",
        "else :\n",
        "    linear_model = load_pkl_file('cache/ml_models/linear_model.pkl')\n",
        "    preds_linear, mae_linear, mse_linear = score_model(linear_model, OH_X_train, OH_X_valid, y_train, y_valid)\n",
        "    print(f\"Mean Absolute Error with Linear Regression: {mae_linear}\")\n",
        "    print(f\"Mean Absolute Error with Linear Regression: {mse_linear}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ridge Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if REFRESH:\n",
        "    # Define a set of alpha values for RidgeCV to search through\n",
        "    alphas = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
        "\n",
        "    # Fit RidgeCV model to find the best alpha value\n",
        "    ridge_cv = RidgeCV(alphas=alphas, cv=5)\n",
        "    ridge_cv.fit(OH_X_train, y_train)\n",
        "\n",
        "    # The best alpha value after cross-validation\n",
        "    best_alpha = ridge_cv.alpha_\n",
        "    print(f\"Best alpha value found: {best_alpha}\")\n",
        "\n",
        "    # Fit Ridge model with the best alpha\n",
        "    ridge_model = Ridge(alpha=best_alpha)\n",
        "    preds_ridge, mae_ridge, mse_ridge = score_model(ridge_model, OH_X_train, OH_X_valid, y_train, y_valid)\n",
        "    print(f\"Mean Absolute Error with Ridge Regression: {mae_ridge}\")\n",
        "    print(f\"Mean Squared Error with Ridge Regression: {mse_ridge}\")\n",
        "\n",
        "    # Save the Ridge model\n",
        "    save_pkl_file(ridge_model, filepath='cache/ml_models/ridge_model.pkl')\n",
        "else:\n",
        "    # Load the saved Ridge model\n",
        "    ridge_model = load_pkl_file('cache/ml_models/ridge_model.pkl')\n",
        "    preds_ridge, mae_ridge, mse_ridge = score_model(ridge_model, OH_X_train, OH_X_valid, y_train, y_valid)\n",
        "    print(f\"Mean Absolute Error with Ridge Regression: {mae_ridge}\")\n",
        "    print(f\"Mean Squared Error with Ridge Regression: {mse_ridge}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XGBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if REFRESH :\n",
        "    #Fit XGboost model\n",
        "    xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=5)\n",
        "    preds_xgboost, mae_xgboost, mse_xgboost = score_model(xgb_model, OH_X_train, OH_X_valid, y_train, y_valid)\n",
        "    print(f\"Mean Absolute Error with XGBoost: {mae_xgboost}\")\n",
        "    print(f\"Mean Squared Error with XGBoost: {mse_xgboost}\")\n",
        "    save_pkl_file(xgb_model, filepath='cache/ml_models/xgb_model.pkl')\n",
        "else :\n",
        "    xgb_model = load_pkl_file('cache/ml_models/xgb_model.pkl')\n",
        "    preds_xgboost, mae_xgboost, mse_xgboost = score_model(xgb_model, OH_X_train, OH_X_valid, y_train, y_valid)\n",
        "    print(f\"Mean Absolute Error with XGBoost: {mae_xgboost}\")\n",
        "    print(f\"Mean Squared Error with XGBoost: {mse_xgboost}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## K-Nearest Neighbours (KNN) Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if REFRESH :\n",
        "    #Fit K-Nearest Neighbours model\n",
        "    knn_regressor = KNeighborsRegressor(n_neighbors=2000)\n",
        "    preds_knn, mae_knn, mse_knn = score_model(knn_regressor, OH_X_train, OH_X_valid, y_train, y_valid)\n",
        "    print(f\"Mean Absolute Error with KNN: {mae_knn}\")\n",
        "    print(f\"Mean Squared Error with KNN: {mse_knn}\")\n",
        "    save_pkl_file(knn_regressor, filepath='cache/ml_models/knn_regressor.pkl')\n",
        "else :\n",
        "    knn_regressor = load_pkl_file('cache/ml_models/knn_regressor.pkl')\n",
        "    preds_knn, mae_knn, mse_knn = score_model(knn_regressor, OH_X_train, OH_X_valid, y_train, y_valid)\n",
        "    print(f\"Mean Absolute Error with KNN: {mae_knn}\")\n",
        "    print(f\"Mean Squared Error with KNN: {mse_knn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-layer Perceptron (MLP) Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if REFRESH :\n",
        "    # Initialize the MLPRegressor model\n",
        "    nn_model = MLPRegressor(hidden_layer_sizes=(128, 64, 32),\n",
        "                            activation='relu',\n",
        "                            solver='adam',\n",
        "                            max_iter=500,\n",
        "                            early_stopping=True, # To use early stopping based on validation score\n",
        "                            validation_fraction=0.2, # Fraction of training data to set aside as validation set for early stopping\n",
        "                            verbose=True,\n",
        "                            random_state=42)\n",
        "    preds_nn, mae_nn, mse_nn = score_model(nn_model, OH_X_train, OH_X_valid, y_train, y_valid)\n",
        "    print(f\"Mean Absolute Error with Neural Network (MLPRegressor): {mae_nn}\")\n",
        "    print(f\"Mean Squared Error with Neural Network (MLPRegressor): {mse_nn}\")\n",
        "    save_pkl_file(nn_model, filepath='cache/ml_models/nn_model.pkl')\n",
        "else :\n",
        "    nn_model = load_pkl_file('cache/ml_models/nn_model.pkl')\n",
        "    preds_nn, mae_nn, mse_nn = score_model(nn_model, OH_X_train, OH_X_valid, y_train, y_valid)\n",
        "    print(f\"Mean Absolute Error with Neural Network (MLPRegressor): {mae_nn}\")\n",
        "    print(f\"Mean Squared Error with Neural Network (MLPRegressor): {mse_nn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Support Vector Regression (SVR) Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if REFRESH :\n",
        "    # Create SVR pipeline\n",
        "    def create_svr_pipeline():\n",
        "        return make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.1, kernel='rbf'))\n",
        "\n",
        "    # Use your score_model function\n",
        "    svr_model = create_svr_pipeline()\n",
        "    preds_svr, mae_svr, mse_svr = score_model(svr_model, OH_X_train, OH_X_valid, y_train, y_valid)\n",
        "    print(f\"Mean Absolute Error with SVR: {mae_svr}\")\n",
        "    print(f\"Mean Squared Error with SVR: {mse_svr}\")\n",
        "    save_pkl_file(svr_model, 'cache/ml_models/svr_model.pkl')\n",
        "else :\n",
        "    svr_model = load_pkl_file('cache/ml_models/svr_model.pkl')\n",
        "    preds_svr, mae_svr, mse_svr = score_model(pipeline, OH_X_train, OH_X_valid, y_train, y_valid)\n",
        "    print(f\"Mean Absolute Error with SVR: {mae_svr}\")\n",
        "    print(f\"Mean Squared Error with SVR: {mse_svr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Baseline Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mean Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the mean of the training target values\n",
        "mean_train = y_train.mean()\n",
        "\n",
        "# Use the mean to make predictions for the validation set\n",
        "mean_preds = [mean_train] * len(y_valid)\n",
        "\n",
        "# Calculate the Mean Absolute Error (MAE) of the mean model\n",
        "mae_mean = mean_absolute_error(y_valid, mean_preds)\n",
        "mse_mean = mean_squared_error(y_valid, mean_preds)\n",
        "\n",
        "print(f\"Mean Absolute Error with Mean Model: {mae_mean}\")\n",
        "print(f\"Mean Squared Error with Mean Model: {mse_mean}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Seasonal Arima X Model (Crashes Kernel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define external regressors. Ensure there are no non-numeric or NaN values.\n",
        "#exog_train = OH_X_train\n",
        "# exog_valid = OH_X_valid\n",
        "\n",
        "# Fit ARIMA-X model (ARIMA with external regressors, without the seasonal component) using the entire dataset\n",
        "# model = ARIMA(y_train, exog=exog_train, order=(1,1,1))\n",
        "#results = model.fit()\n",
        " \n",
        "# Forecast\n",
        "#forecast = results.predict(start=len(y_train), end=len(y_train) + len(y_valid) - 1, exog=exog_valid, dynamic=True)\n",
        "\n",
        "# Calculate MAE\n",
        "# mae_arimax = mean_absolute_error(y_valid, forecast)\n",
        "\n",
        "# print(f\"Mean Absolute Error with ARIMA-X: {mae_arimax}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#used sample data set as the full data crashes the kernel\n",
        "# if REFRESH :\n",
        "#     exog_train = OH_X_train\n",
        "#     exog_valid = OH_X_valid\n",
        "#     # Fit auto_arima model\n",
        "#     s_arimax_model = auto_arima(y_train, exogenous=exog_train,\n",
        "#                         seasonal=True, m=7,  # m is the seasonal period\n",
        "#                         stepwise=True, trace=True,\n",
        "#                         suppress_warnings=True, error_action='ignore')\n",
        "\n",
        "#     print(s_arimax_model.summary())\n",
        "    \n",
        "#     forecast = s_arimax_model.predict(n_periods=len(y_valid), exogenous=exog_valid)\n",
        "#     mae_arimax = mean_absolute_error(y_valid, forecast)\n",
        "#     mse_arimax = mean_squared_error(y_valid, forecast)\n",
        "    \n",
        "#     print(f\"Mean Absolute Error with Seasonal ARIMA-X: {mae_arimax}\")\n",
        "#     print(f\"Mean Squared Error with Seasonal ARIMA-X: {mae_arimax}\")\n",
        "    \n",
        "#     save_pkl_file(s_arimax_model, 'cache/ml_models/s_arimax_model.pkl')\n",
        "# else :\n",
        "#     s_arimax_model = load_pkl_file('cache/ml_models/s_arimax_model.pkl')\n",
        "#     forecast = s_arimax_model.predict(n_periods=len(y_valid), exogenous=exog_valid)\n",
        "#     mae_arimax = mean_absolute_error(y_valid, forecast)\n",
        "#     mse_arimax = mean_squared_error(y_valid, forecast)\n",
        "#     print(f\"Mean Absolute Error with Seasonal ARIMA-X: {mae_arimax}\")\n",
        "#     print(f\"Mean Squared Error with Seasonal ARIMA-X: {mse_arimax}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Persistence Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The persistence prediction for the first point in the validation set is the last point in the training set\n",
        "# For subsequent points in the validation set, the prediction is the previous point in the validation set itself\n",
        "persistence_preds = [y_train.iloc[-1]] + list(y_valid.iloc[:-1])\n",
        "\n",
        "# Calculate the Mean Absolute Error (MAE) and Mean Squared Error (MSE) of the persistence model\n",
        "mae_persistence = mean_absolute_error(y_valid, persistence_preds)\n",
        "mse_persistence = mean_squared_error(y_valid, persistence_preds)\n",
        "\n",
        "print(f\"Mean Absolute Error with Persistence Model: {mae_persistence}\")\n",
        "print(f\"Mean Squared Error with Persistence Model: {mse_persistence}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare with Baseline Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dictionaries for MAE and MSE values\n",
        "mae_values = {\n",
        "    'Linear': mae_linear,\n",
        "    'Ridge' : mae_ridge,\n",
        "    'XGBoost': mae_xgboost,\n",
        "    'KNN': mae_knn,\n",
        "    'SVR': mae_svr,\n",
        "    'NN': mae_nn,\n",
        "    'Mean Model': mae_mean,\n",
        "    'Persistence Model': mae_persistence\n",
        "}\n",
        "\n",
        "mse_values = {\n",
        "    'Linear': mse_linear,\n",
        "    'Rdige' : mse_ridge,\n",
        "    'XGBoost': mse_xgboost,\n",
        "    'KNN': mse_knn,\n",
        "    'SVR': mse_svr,\n",
        "    'NN': mse_nn,\n",
        "    'Mean Model': mse_mean,\n",
        "    'Persistence Model': mse_persistence\n",
        "}\n",
        "\n",
        "# Sort the dictionaries by their values\n",
        "sorted_mae = dict(sorted(mae_values.items(), key=lambda item: item[1]))\n",
        "sorted_mse = dict(sorted(mse_values.items(), key=lambda item: item[1]))\n",
        "\n",
        "# Define colors for models (you can change colors if you want)\n",
        "colors = ['lightgrey' if model in ['Mean Model', 'Persistence Model'] else 'lightblue' for model in sorted_mae.keys()]\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
        "\n",
        "# Plot MAE\n",
        "mae_bars = axes[0].barh(list(sorted_mae.keys()), list(sorted_mae.values()), color=colors)\n",
        "axes[0].set_xlabel('Mean Absolute Error (MAE)')\n",
        "axes[0].set_title('Model Comparison based on MAE')\n",
        "\n",
        "# Plot MSE\n",
        "mse_bars = axes[1].barh(list(sorted_mse.keys()), list(sorted_mse.values()), color=colors)\n",
        "axes[1].set_xlabel('Mean Squared Error (MSE)')\n",
        "axes[1].set_title('Model Comparison based on MSE')\n",
        "\n",
        "# Annotate bars with the actual values\n",
        "for ax in axes:\n",
        "    for bar in ax.patches:\n",
        "        ax.text(bar.get_width(), bar.get_y() + bar.get_height() / 2,\n",
        "                f'{bar.get_width():.4f}',\n",
        "                va='center', ha='right', color='black', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. Feature Tuning - Optimal Number of Topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to compute coherence values for different numbers of topics\n",
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values\n",
        "\n",
        "# Variables (set 'limit' to the maximum number of topics you want to test)\n",
        "start, limit, step = 2, 40, 1\n",
        "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=ml_df['tokens'], start=start, limit=limit, step=step)\n",
        "\n",
        "# Show graph\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()\n",
        "\n",
        "# Print the coherence scores\n",
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))\n",
        "\n",
        "# Select the model with the highest coherence and print the topics\n",
        "best_topic_num = x[coherence_values.index(max(coherence_values))]\n",
        "best_model = model_list[coherence_values.index(max(coherence_values))]\n",
        "print(f'Optimal number of topics: {best_topic_num}')\n",
        "print(best_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8.  Hyperparameter Tuning for Machine Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 9. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10. Portfolio Analytics Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calc_annualised_returns(cumulative_returns:float, n, frequency):\n",
        "    if frequency == \"D\":\n",
        "        t = 252\n",
        "    elif frequency == \"M\":\n",
        "        t = 12\n",
        "    return ((cumulative_returns + 1)**(t/n) - 1).values[0]\n",
        "\n",
        "def calc_annualised_vol(ptf_rtn: pd.Series, frequency):\n",
        "    if frequency == \"D\":\n",
        "        n = 252 # 252 trading days in ptf_rtn\n",
        "    elif frequency == \"M\":\n",
        "        n = 12\n",
        "    return ptf_rtn.std(ddof=1).values[0] * np.sqrt(n)\n",
        "\n",
        "def calc_max_dd(ptf_rtn: pd.Series):\n",
        "    # Cumulative returns must be base 1\n",
        "    ptf_cumulative_return = (1+ptf_rtn).cumprod()\n",
        "\n",
        "    # Calculate running max\n",
        "    running_max = ptf_cumulative_return.cummax()\n",
        "\n",
        "    # Drawdown\n",
        "    drawdown = (ptf_cumulative_return-running_max)/running_max\n",
        "\n",
        "    max_drawdown = drawdown.min().values[0]\n",
        "    return max_drawdown\n",
        "\n",
        "def calc_ptf_summary(ptf_rtn):\n",
        "    ptf_cum_rtn = (ptf_rtn+1).prod()-1\n",
        "    ptf_ann_rtn = calc_annualised_returns(ptf_cum_rtn, len(ptf_rtn), 'D')\n",
        "    ptf_ann_vol = calc_annualised_vol(ptf_rtn, \"D\")\n",
        "    ptf_max_dd = calc_max_dd(ptf_rtn)\n",
        "    sharpe_ratio = ptf_ann_rtn/ptf_ann_vol\n",
        "    downside_sd = ptf_rtn[ptf_rtn < 0].std()[0]\n",
        "    sortino_ratio = ptf_ann_rtn/downside_sd\n",
        "    return pd.DataFrame({\n",
        "        'Metrics': ['Cumulative Returns', 'Annualised Returns',\n",
        "                    'Annualised Volatility', 'Maximum Drawdown',\n",
        "                    'Sharpe Ratio', 'Sortino Ratio'],\n",
        "        'Values': [format(ptf_cum_rtn[0],\".2%\"),\n",
        "                   format(ptf_ann_rtn, \".2%\"),\n",
        "                   format(ptf_ann_vol, \".2%\"),\n",
        "                   format(ptf_max_dd, \".2%\"),\n",
        "                   format(sharpe_ratio, \".2f\"),\n",
        "                   format(sortino_ratio, \".2f\")]\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 11.0 Modern Portfolio Theory Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11.1 Solving for Maximum Sharpe Ratio Point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Formulation of the Optimization Problem for Maximizing Sharpe Ratio:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Objective:  $$ \\text{max }_{w \\in \\mathbb{R}^n} \\frac{\\mu^T w - r_{f}}{ \\sqrt{w^T Q w}}$$\n",
        "\n",
        "Constriants:\n",
        "\n",
        "1) budget constraint: $$ \\textbf{1}^T w = 1 $$\n",
        "2) nonnegative constraint: $$w \\geq 0$$\n",
        "\n",
        "where:\n",
        "- $w$ = vector for weights (amount of investment)\n",
        "- $\\mu$ is the vector for expected return \n",
        "- $r_{f}$ is the risk-free rate\n",
        "- $Q$ = covariance matrix\n",
        "- $\\textbf{1}$ = vector of 1's"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE: In our trading models, we assume that risk free rate is 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating a class for maximising sharpe ratio\n",
        "class MaximiseSR():\n",
        "    def __init__(self, data) -> None:\n",
        "        self.data = data\n",
        "        self.data_cov_mat = self.data.cov()\n",
        "\n",
        "    @staticmethod\n",
        "    def ann_ret(x):\n",
        "        return (x+1)**252-1\n",
        "\n",
        "    @staticmethod\n",
        "    def ann_std(x):\n",
        "        return x*np.sqrt(252)\n",
        "\n",
        "    @staticmethod\n",
        "    def PVol(w, cov_mat):\n",
        "        pvar = w @ cov_mat @ w\n",
        "        return np.sqrt(pvar)\n",
        "\n",
        "    def annualised_sr(self, w):\n",
        "        excess_ret = self.data @ w\n",
        "        AnnSR = self.ann_ret(excess_ret.mean())/self.ann_std(self.PVol(w))\n",
        "        return AnnSR\n",
        "\n",
        "    # Function to find the optimal portfolio that maximize the Sharpe ratio\n",
        "    # Returns the optimal solution\n",
        "    def gen_solution(self, silent = False):\n",
        "\n",
        "        # Objective Function\n",
        "        def SR(w):\n",
        "            excess_ret = self.data @ w\n",
        "            SR = (excess_ret.mean())/(self.PVol(w, self.data_cov_mat))\n",
        "            return -SR\n",
        "\n",
        "        n = len(self.data.columns)\n",
        "\n",
        "        # Bounds\n",
        "        bnds = tuple((0,1) for i in range(n)) # nonnegativity constraint\n",
        "\n",
        "        # Constraints\n",
        "        def constraint1(w):\n",
        "            return np.sum(w) - 1.0 # budget constraint\n",
        "        cons = {'type': 'eq', 'fun': constraint1}\n",
        "\n",
        "        # Initial x0; the initial guess for the solution\n",
        "        w0 = np.array(np.ones(n))\n",
        "\n",
        "        # Solve the problem\n",
        "        # Using the Sequential Least Squares Quadratic Programming method\n",
        "        sol = minimize(SR, w0, method='SLSQP', bounds=bnds, constraints=cons)\n",
        "\n",
        "        # Whether the solution will be printed\n",
        "        if(not silent):\n",
        "            print(\"Solution to the Max Sharpe Ratio Problem is:\")\n",
        "            print(sol)\n",
        "            print(\"\")\n",
        "        elif (not sol['success']): #check if the optimizer exist successfully\n",
        "            print(\"WARNING:  the optimizer did NOT exit successfully!!\")\n",
        "        return sol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 12.0 Evaluating trading performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12.1 Backtest Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a Backtest class to house all the functions needed for backtesting our machine learning powered trading strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In particular we construct 4 main portfolios:\n",
        "1. Dollar Neutral Long-Short Portfolio\n",
        "2. Dollar Long Only Portfolio\n",
        "3. Dollar Long Only Optimised Portfolio\n",
        "4. Equal Weighted Portfolio (Benchmark)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Backtest():\n",
        "    \"\"\"\n",
        "    This Class generates the portfolio weights for a Long Short, Long Only, Long Only Optimised, and Equal Weight strategy.\n",
        "    It also calculates summary statistics for each portfolio, and plots the cumulative returns of each strategy.\n",
        "    \\n\n",
        "    Example:\n",
        "    \\n\n",
        "    ```\n",
        "    # Instantiate backtester, where linear_model is a fitted linear regression model\n",
        "    backtester = Backtest(linear_model, \"LINEAR MODEL\", rtn_df, OH_X_train, y_train, OH_X_valid, X_valid)\n",
        "\n",
        "    # Display the summary statistics in a dataframe, and plots the cumulative returns for all 4 portfolios.\n",
        "    backtester.display_results()\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, fitted_model, model_name, rtn_df, OH_X_train, y_train, OH_X_valid, X_valid):\n",
        "        self.model = fitted_model\n",
        "        self.model_name = model_name\n",
        "        self.rtn_df = rtn_df\n",
        "        self.OH_X_train = OH_X_train\n",
        "        self.OH_X_valid = OH_X_valid\n",
        "        self.y_train = y_train\n",
        "        self.X_valid = X_valid\n",
        "\n",
        "        # Generate signal dataframe\n",
        "        self.sig_df =  self.gen_signals_df()\n",
        "\n",
        "        # Construct long short portfolio\n",
        "        self.ls_ptf_wgt = self.constr_ls_ptf_wgt()\n",
        "\n",
        "        # Construct long only portfolio\n",
        "        self.lo_ptf_wgt = self.constr_lo_ptf_wgt()\n",
        "\n",
        "        # Construct equal weighted portfolio\n",
        "        self.eq_ptf_wgt = self.constr_eq_ptf_wgt()\n",
        "\n",
        "        # Construct optimal weights portfolio\n",
        "        self.opt_ptf_wgt = self.constr_opt_ptf_wgt()\n",
        "\n",
        "        # Generate backtest analytics\n",
        "        self.ptf_rtn_combined, self.cum_rtn_fig, self.summary_metrics = self.gen_backtest_analytics()\n",
        "\n",
        "    def gen_signals_df(self):\n",
        "        preds = self.model.predict(self.OH_X_valid)\n",
        "        trading_df = self.X_valid.copy()\n",
        "\n",
        "        # Create column of predicted returns\n",
        "        trading_df['predicted_rtn'] = preds\n",
        "\n",
        "        # Count number of stocks per date\n",
        "        trading_df['num_stocks_by_date'] = trading_df.groupby('date').transform('size')\n",
        "\n",
        "        # Select data where there were at least 10 stocks for each date\n",
        "        trading_df_filtered = trading_df[trading_df['num_stocks_by_date'] >= 10]\n",
        "\n",
        "        trading_df_filtered = trading_df_filtered[['date', 'stock', 'predicted_rtn']].reset_index(drop=True)\n",
        "\n",
        "        # Handle duplicated stocks on a single date (stems from multiple headline for a stock on one day)\n",
        "        trading_df_filtered_dd = trading_df_filtered.groupby(['date', 'stock'])['predicted_rtn'].mean().reset_index(name='predicted_rtn')\n",
        "\n",
        "        # Create daily index and forward fill\n",
        "        start_date = trading_df_filtered_dd['date'].min()\n",
        "        end_date = trading_df_filtered_dd['date'].max()\n",
        "\n",
        "        # Reesample to daily\n",
        "        daily_index = pd.date_range(start=start_date, end=end_date, freq='B')\n",
        "\n",
        "        # Pivot dataframe to forward fill to daily index so that we have signals everyday\n",
        "        trading_df_filtered_wide = trading_df_filtered_dd.pivot(index='date', values='predicted_rtn', columns='stock')\n",
        "        trading_df_filtered_wide = trading_df_filtered_wide.reindex(daily_index).fillna(method='ffill')\n",
        "\n",
        "        final_signal_df = (trading_df_filtered_wide\n",
        "                        .reset_index(names='date')\n",
        "                        .rename_axis(None, axis=1)\n",
        "                        .melt(id_vars='date', var_name='stock', value_name='signal')\n",
        "                        .dropna(axis=0).reset_index(drop=True))\n",
        "        final_signal_df = final_signal_df.rename(columns={\n",
        "            'date': 'DATE',\n",
        "            'stock': 'ID',\n",
        "            'signal': 'SIGNAL'\n",
        "        })\n",
        "        return final_signal_df\n",
        "\n",
        "    def constr_ls_ptf_wgt(self):\n",
        "        # Create copy of sig_df\n",
        "        sig_df = self.sig_df.copy()\n",
        "\n",
        "        # Ranking the signals to reduce fat tails\n",
        "        sig_df['RANKED_SIGNAL'] = sig_df.groupby('DATE')['SIGNAL'].transform(lambda x: scipy.stats.rankdata(x))\n",
        "        sig_df = sig_df.sort_values(['DATE', 'ID']).reset_index(drop=True)\n",
        "\n",
        "        # Long short weights calculated as the distance for median signal for each date\n",
        "        sig_df['WGT'] = sig_df.groupby(['DATE'])['RANKED_SIGNAL'].transform(lambda x: x-x.median())\n",
        "\n",
        "        # Renormalise weights to $1 long $1 short  dollar neutral strategy\n",
        "        sig_df['DIRECTION'] = np.where(sig_df['WGT']>=0, 'LONG', 'SHORT')\n",
        "        sig_df['RENORM_WGT'] = sig_df.groupby(['DATE', 'DIRECTION'])['WGT'].transform(lambda x: x/np.abs(x.sum()))\n",
        "        return sig_df[['DATE', 'ID', 'RENORM_WGT']].rename(columns={'RENORM_WGT': 'WGT'})\n",
        "\n",
        "    def constr_lo_ptf_wgt(self):\n",
        "        # Create copy of sig_df\n",
        "        sig_df = self.sig_df.copy()\n",
        "\n",
        "        # Create long only signal df\n",
        "        sig_df_lo = sig_df[sig_df['SIGNAL']>0].copy()\n",
        "\n",
        "        # Reset index\n",
        "        sig_df_lo = sig_df_lo.reset_index(drop=True)\n",
        "\n",
        "        # Use predicted returns as weights\n",
        "        sig_df_lo['WGT'] = sig_df_lo.groupby('DATE')['SIGNAL'].transform(lambda x: x/x.sum())\n",
        "        return sig_df_lo[['DATE', 'ID', 'WGT']]\n",
        "\n",
        "    def constr_eq_ptf_wgt(self):\n",
        "        # Create copy of sig_df\n",
        "        sig_df = self.sig_df.copy()\n",
        "\n",
        "        # Use predicted returns as weights\n",
        "        sig_df['WGT'] = sig_df.groupby('DATE')['ID'].transform(lambda x: 1/x.shape[0])\n",
        "        return sig_df[['DATE', 'ID', 'WGT']]\n",
        "\n",
        "    def constr_opt_ptf_wgt(self):\n",
        "        sig_df = self.sig_df.copy()\n",
        "        pred_rtn_df = sig_df.pivot(index='DATE', columns='ID', values='SIGNAL').rename_axis(None, axis=1)\n",
        "\n",
        "        # Not all stocks have predicted returns at every time step\n",
        "        # This is because of the lack of regressor data on those dates\n",
        "        # like not having sentiment scores etc.\n",
        "\n",
        "        # We fill 0 returns for those day\n",
        "        pred_rtn_df = pred_rtn_df.fillna(0)\n",
        "\n",
        "        # Find the optimal portfolio that maximize Sharpe Ratio\n",
        "        MaxSR = MaximiseSR(pred_rtn_df)\n",
        "        opt_sol = MaxSR.gen_solution(silent=True)\n",
        "\n",
        "        # Retrieve optimal weights\n",
        "        opt_sol_wgt_df = pd.DataFrame({\"ID\": pred_rtn_df.columns, \"WGT\": opt_sol['x']})\n",
        "\n",
        "        # Generate optimal solution's portfolio dataframe\n",
        "        pred_rtn_df_melt = pred_rtn_df.reset_index().melt(var_name='ID', id_vars='DATE', value_name='PRED_RTN')\n",
        "        opt_wgt_df = pd.merge(pred_rtn_df_melt, opt_sol_wgt_df, on='ID')\n",
        "        return opt_wgt_df.drop(columns='PRED_RTN')\n",
        "\n",
        "    def calc_ptf_rtn(self, ptf_wgt):\n",
        "        # Merge ls weights on returns  left join\n",
        "        ptf_df = pd.merge(ptf_wgt, self.rtn_df, on=['DATE', 'ID'], how='left')\n",
        "\n",
        "        # On dates without returns just set returns to 0\n",
        "        ptf_df = ptf_df.fillna(0)\n",
        "\n",
        "        # Shift weights by 1 to imply lag\n",
        "        ptf_df['WGT_SHIFTED'] = ptf_df['WGT'].shift(1)\n",
        "\n",
        "        # Calculate weighted returns\n",
        "        ptf_df['WGT_RTN'] = ptf_df['WGT_SHIFTED'] * ptf_df['RTN']\n",
        "\n",
        "        # Drop NaN values from shifting\n",
        "        ptf_df = ptf_df.dropna()\n",
        "\n",
        "        ptf_rtn = ptf_df.groupby('DATE')['WGT_RTN'].sum().reset_index(name='PTF_RTN')\n",
        "        return ptf_rtn\n",
        "\n",
        "    def gen_backtest_analytics(self):\n",
        "        self.ls_ptf_rtn = self.calc_ptf_rtn(self.ls_ptf_wgt)\n",
        "        self.ls_ptf_rtn['PORT'] = \"Long Short Portfolio\"\n",
        "\n",
        "        self.lo_ptf_rtn = self.calc_ptf_rtn(self.lo_ptf_wgt)\n",
        "        self.lo_ptf_rtn['PORT'] = \"Long Only Portfolio\"\n",
        "\n",
        "        self.eq_ptf_rtn = self.calc_ptf_rtn(self.eq_ptf_wgt)\n",
        "        self.eq_ptf_rtn['PORT'] = \"Equal Weighted Portfolio\"\n",
        "\n",
        "        self.opt_ptf_rtn = self.calc_ptf_rtn(self.opt_ptf_wgt)\n",
        "        self.opt_ptf_rtn['PORT'] = \"Optimally Weighted Portfolio\"\n",
        "\n",
        "        ptf_rtn_combined = pd.concat([self.ls_ptf_rtn, self.lo_ptf_rtn, self.eq_ptf_rtn, self.opt_ptf_rtn], axis=0)\n",
        "\n",
        "        # Cumulate portfolio returns\n",
        "        ptf_rtn_combined['CUM_RTN'] = ptf_rtn_combined.groupby(['PORT'])['PTF_RTN'].transform(lambda x: (1+x).cumprod()-1)\n",
        "\n",
        "        # Generate cumulative returns figure\n",
        "        fig = px.line(ptf_rtn_combined, x='DATE', y='CUM_RTN', color='PORT')\n",
        "        fig.update_layout(hovermode='x unified',\n",
        "                          title=f\"Portfolio Performance <br><sup>{self.model_name}</sup>\",\n",
        "                          yaxis_title='Cumulative Returns',\n",
        "                          yaxis_tickformat=',.0%')\n",
        "        fig.add_hline(y=0, line_dash='dash')\n",
        "\n",
        "        # Create summary metrics table\n",
        "        summary_metrics = (ptf_rtn_combined.groupby('PORT')\n",
        "                            .apply(lambda x: calc_ptf_summary(x.set_index('DATE')))\n",
        "                            .reset_index(level=0)\n",
        "                            .pivot(index='Metrics', columns='PORT', values='Values')\n",
        "                            .reset_index().rename_axis(None, axis=1)\n",
        "                            )\n",
        "        return ptf_rtn_combined, fig, summary_metrics\n",
        "\n",
        "    def display_results(self):\n",
        "        display(self.summary_metrics)\n",
        "        self.cum_rtn_fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12.1 Interactive Portfolio Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OH_X_train = load_pkl_file('cache/dataframes/OH_X_train.pkl')\n",
        "y_train = load_pkl_file('cache/dataframes/y_train.pkl')\n",
        "OH_X_valid = load_pkl_file('cache/dataframes/OH_X_valid.pkl')\n",
        "X_valid = load_pkl_file('cache/dataframes/X_valid.pkl')\n",
        "returns_df = load_pkl_file('cache/dataframes/returns_df.pkl')\n",
        "returns_df_melt = load_pkl_file('cache/dataframes/returns_df_melt.pkl')\n",
        "rtn_df = returns_df_melt.rename(columns={'date': 'DATE', 'stock': 'ID', 'daily_returns': 'RTN'})\n",
        "rtn_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dropdown = widgets.Dropdown(options=os.listdir('cache/ml_models/'))\n",
        "def on_dropdown_change(change):\n",
        "    model = change['new']\n",
        "    clear_output()\n",
        "    display(dropdown)\n",
        "    model_name = model.split('.')[0].replace('_', \" \").capitalize()\n",
        "    ml_model = load_pkl_file(f'cache/ml_models/{model}')\n",
        "    backtester = Backtest(ml_model, model_name, rtn_df, OH_X_train, y_train, OH_X_valid, X_valid)\n",
        "    backtester.display_results()\n",
        "\n",
        "display(dropdown)\n",
        "dropdown.observe(on_dropdown_change, names='value')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 13.0 Run simulation for all the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run all models trading performance\n",
        "backtested_summ_metrics = []\n",
        "backtested_cum_rtn = []\n",
        "keys = []\n",
        "for model in os.listdir('cache/ml_models/'):\n",
        "    model_name = model.split('.')[0].upper()\n",
        "    ml_model = load_pkl_file(f'cache/ml_models/{model}')\n",
        "    backtester = Backtest(ml_model, model_name, rtn_df, OH_X_train, y_train, OH_X_valid, X_valid)\n",
        "    keys.append(model_name)\n",
        "    backtested_summ_metrics.append(backtester.summary_metrics)\n",
        "    backtested_cum_rtn.append(backtester.ptf_rtn_combined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13.1 Comapre ML Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We want to compare machine learning model's performance, so we keep the strategy constant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_ml_model_performance(list_summ_metrics: list, ml_model_names: list, list_cum_rtn: list, strategy: str=None):\n",
        "    final_metrics_list = []\n",
        "    final_cum_rtn_list = []\n",
        "    df_columns = [\"Metrics\", strategy]\n",
        "    for summ_metrics, cum_rtn, model in zip(list_summ_metrics, list_cum_rtn, ml_model_names):\n",
        "        # Build the combined dataframe for summary statistics\n",
        "        if strategy is not None:\n",
        "            df = summ_metrics[df_columns].copy()\n",
        "        final_metrics_list.append(df.set_index('Metrics'))\n",
        "\n",
        "        # Build the datafrme for combined cumulative returns figure\n",
        "        if strategy is not None:\n",
        "            df = cum_rtn[cum_rtn['PORT']==strategy]\n",
        "            df = df.drop(columns='PORT')\n",
        "            df['ML_MODEL'] = model\n",
        "            final_cum_rtn_list.append(df)\n",
        "\n",
        "    combined_summ_metrics_df = pd.concat(final_metrics_list, axis=1, keys=ml_model_names)\n",
        "    combined_cum_rtn_df = pd.concat(final_cum_rtn_list, axis=0)\n",
        "    fig = px.line(combined_cum_rtn_df, x='DATE', y='CUM_RTN', color='ML_MODEL')\n",
        "    fig.update_layout(hovermode='x unified',\n",
        "                        title=f\"Portfolio Performance <br><sup>{strategy}</sup>\",\n",
        "                        yaxis_title='Cumulative Returns',\n",
        "                        legend_title=\"Machine Learning Model\",\n",
        "                        yaxis_tickformat=',.0%')\n",
        "    fig.add_hline(y=0, line_dash='dash')\n",
        "    return combined_summ_metrics_df, fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "strategies = ['Long Short Portfolio',\n",
        "              'Long Only Portfolio',\n",
        "              'Equal Weighted Portfolio',\n",
        "              'Optimally Weighted Portfolio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display optimally weighted portfolio strategy\n",
        "combined_summ_metrics_df, fig = compare_ml_model_performance(backtested_summ_metrics, keys, backtested_cum_rtn, strategy=strategies[-1])\n",
        "display(combined_summ_metrics_df)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display all strategies\n",
        "for strat in strategies:\n",
        "    combined_summ_metrics_df, fig = compare_ml_model_performance(backtested_summ_metrics, keys, backtested_cum_rtn, strategy=strat)\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
