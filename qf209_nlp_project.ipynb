{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_mdkZqU2Zhnq",
        "outputId": "4ce0b414-8d9d-4f4d-8fd2-932158169f7f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import yfinance as yf\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_1 = pd.read_csv(\"data/daily_financial_news/analyst_ratings_processed.csv\", index_col=0)\n",
        "data_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_1['date'] = data_1['date'].str.split(' ', expand=True).iloc[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_1['stock'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVlMohoBlTJQ",
        "outputId": "15579c96-a538-480e-cf36-81553f02c734"
      },
      "outputs": [],
      "source": [
        "data_1.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Drop Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKt6rDWBlk8l",
        "outputId": "9512fd8d-8077-4237-937c-e87a35976c89"
      },
      "outputs": [],
      "source": [
        "print(data_1.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9pDiHR3nCvC",
        "outputId": "606a9af2-c319-4559-b501-5f7cdd954638"
      },
      "outputs": [],
      "source": [
        "print(data_1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_1[data_1['date'].isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV5Xn1-2oMTG"
      },
      "outputs": [],
      "source": [
        "data_1.dropna(subset=['date'],inplace=True)\n",
        "data_1.dropna(subset=['stock'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkszMKzlpVnL",
        "outputId": "f2b99e34-dab9-4f73-805c-c1db92b21862"
      },
      "outputs": [],
      "source": [
        "print(data_1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG6ydygqpZx1",
        "outputId": "9fff9776-66d4-42ad-9307-309dd0fbd9f6"
      },
      "outputs": [],
      "source": [
        "print(data_1.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lthUY-R-phFG",
        "outputId": "39c496c4-1489-4457-93e0-5e88c8054b29"
      },
      "outputs": [],
      "source": [
        "data_1.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filter stocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter dataset down to stocks with top 100 number of headlines\n",
        "top_100_stocks_by_headlines = data_1.groupby('stock').size().reset_index(name='size').sort_values('size', ascending=False).reset_index(drop=True).iloc[:100]\n",
        "top_100_stocks_by_headlines.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_1 = data_1[data_1['stock'].isin(top_100_stocks_by_headlines.stock)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean Text Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bysKZg9qtnrg"
      },
      "outputs": [],
      "source": [
        "data_1['title'] = data_1['title'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "j0Ci37Nwt9fX",
        "outputId": "027046b6-7432-4457-8727-aebebc71e119"
      },
      "outputs": [],
      "source": [
        "data_1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Remove Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jUv6dT5vpIp"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return ''.join([char for char in text if char not in string.punctuation and not char.isdigit()])\n",
        "\n",
        "data_1['title'] = data_1['title'].apply(remove_punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hHyB2atzvvgq",
        "outputId": "9c27a854-4218-4cd1-9f3f-c40293e8d38a"
      },
      "outputs": [],
      "source": [
        "data_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GdlIDQsTwJxt",
        "outputId": "3c5dfcd6-b1f5-4462-92e0-24d99fcaf567"
      },
      "outputs": [],
      "source": [
        "data_1['tokens'] = data_1['title'].apply(lambda x: x.split())\n",
        "data_1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Remove stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUEjDSAwwSjK",
        "outputId": "4b5df763-3a4c-42db-ad0a-ff33b2c5c7aa"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "data_1['tokens'] = data_1['tokens'].apply(lambda x: [word for word in x if word not in stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mkPxf-CgwozT",
        "outputId": "2b6e2cf8-d361-48eb-ae5b-70632f6547dd"
      },
      "outputs": [],
      "source": [
        "data_1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lemmatize tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7fTt-K3xJvz",
        "outputId": "5c7566e1-e106-4449-ea98-8f15cb9a1c93"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "data_1['tokens'] = data_1['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "15KCoy4qxkxx",
        "outputId": "dc3de5f1-a6b2-4628-ac4d-a94ac0f98b39"
      },
      "outputs": [],
      "source": [
        "data_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XUau0f0GxULI",
        "outputId": "2bc02e85-0e41-43ce-bc32-64d619832a29"
      },
      "outputs": [],
      "source": [
        "data_1['preprocessed_text'] = data_1['tokens'].apply(' '.join)\n",
        "data_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDMEu5K2x4L6",
        "outputId": "20fc393c-bef0-41bf-ce79-d63044de3c74"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "# NLTK Sentiment Intensity Analyzer uses a 'Bag of Words' approach\n",
        "# it removes stop words and scores each word individually before compounding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_duplicate = data_1.copy()\n",
        "data_duplicate['sentiment_score'] = data_duplicate['preprocessed_text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
        "data_duplicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0nlV-P20K_8",
        "outputId": "2c43f90d-c726-46e3-c5d3-999274766fdf"
      },
      "outputs": [],
      "source": [
        "data_duplicate['sentiment_score'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGBvIQCZ2Ew6",
        "outputId": "ce24972b-4612-4b4d-86f8-32e1d288a9c0"
      },
      "outputs": [],
      "source": [
        "data_duplicate.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_duplicate.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signals_df = data_duplicate[['date', 'stock', 'sentiment_score']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signals_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# There are some stocks that have multiple news articles on the same day\n",
        "# Have to handle these cases\n",
        "non_dup_signals_df = signals_df.groupby(['date', 'stock'])['sentiment_score'].mean().reset_index(name='sentiment_score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pull yfinance data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tickers = data_duplicate.stock.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_date, end_date = data_duplicate.date.sort_values().iloc[0], data_duplicate.date.sort_values().iloc[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = yf.download(list(tickers), start=start_date, end=end_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "adj_close_data = data['Adj Close']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tickers that don't have data\n",
        "missing_data_tickers = adj_close_data.columns[adj_close_data.isna().sum()/adj_close_data.shape[0] == 1]\n",
        "\n",
        "# Drop missing tickers\n",
        "adj_close_data = adj_close_data.drop(columns=missing_data_tickers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop other tickers\n",
        "adj_close_data = adj_close_data.dropna(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "any(adj_close_data.isna().sum() > 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "returns_df = adj_close_data.pct_change().dropna().reset_index().rename(columns={'Date': 'date'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "returns_df_melt = returns_df.melt(id_vars='date', var_name='stock', value_name='daily_returns')\n",
        "returns_df_melt['date'] = pd.to_datetime(returns_df_melt['date'])\n",
        "returns_df_melt.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "non_dup_signals_df.sort_values('date').head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "returns_df_melt.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "non_dup_signals_df['date'] = pd.to_datetime(non_dup_signals_df['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_df = pd.merge(returns_df_melt, non_dup_signals_df, on=['date', 'stock'], how='left').dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build Machine Learning Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split Data into Features and Target\n",
        "# Sort values by date\n",
        "X = ml_df.sort_values(\"date\").drop('daily_returns', axis=1).reset_index(drop=True)\n",
        "y = ml_df.sort_values(\"date\")['daily_returns'].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ts_train_test_split(data, test_size):\n",
        "    \"\"\"Takes in data and output train set and test set in that order\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame or pd.Series): Data to split into train and test\n",
        "        test_size (float): Percentage for test size\n",
        "\n",
        "    Returns:\n",
        "        tuple: train set, test set\n",
        "    \"\"\"\n",
        "    train_size = 1-test_size\n",
        "    train_idx = round(X.shape[0] * train_size)\n",
        "    return data.iloc[:train_idx], data.iloc[train_idx:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split Data into Training and Validation Sets\n",
        "X_train, X_valid = ts_train_test_split(X, test_size=0.2)\n",
        "y_train, y_valid = ts_train_test_split(y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "\n",
        "# One-hot Encode 'stock' Column for Training and Validation Data\n",
        "OH_cols_train = pd.DataFrame(one_hot_encoder.fit_transform(X_train[['stock']]))\n",
        "OH_cols_valid = pd.DataFrame(one_hot_encoder.transform(X_valid[['stock']]))\n",
        "\n",
        "# Assign Column Names after One-Hot Encoding and Restore Index\n",
        "OH_cols_train.columns = one_hot_encoder.get_feature_names_out(['stock'])\n",
        "OH_cols_valid.columns = one_hot_encoder.get_feature_names_out(['stock'])\n",
        "OH_cols_train.index, OH_cols_valid.index = X_train.index, X_valid.index\n",
        "\n",
        "# Remove Original 'stock' Column\n",
        "num_X_train = X_train.drop('stock', axis=1)\n",
        "num_X_valid = X_valid.drop('stock', axis=1)\n",
        "\n",
        "# Concatenate Original Data with One-Hot Encoded Columns\n",
        "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
        "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
        "\n",
        "# Ensure all columns have string type\n",
        "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
        "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
        "\n",
        "# Ensure 'date' is in datetime format if it is used in further analyses\n",
        "OH_X_train = OH_X_train.drop(columns=['date'])\n",
        "OH_X_valid = OH_X_valid.drop(columns=['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def score_model(model, X_t, X_v, y_t, y_v):\n",
        "    # Fit Model\n",
        "    model.fit(X_t, y_t)\n",
        "\n",
        "    # Predict\n",
        "    preds = model.predict(X_v)\n",
        "\n",
        "    # Check MAE\n",
        "    mae = mean_absolute_error(preds, y_v)\n",
        "    return mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "linear_model = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "score_model(linear_model, OH_X_train, OH_X_valid, y_train, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
